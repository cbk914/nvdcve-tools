#! /usr/bin/env python3
# -*- coding: utf-8 -*-
# Author: cbk914
import requests
import re
import sys
import argparse
import logging
import os
import hashlib
import zipfile
import concurrent.futures
import datetime
import json
import csv

logging.basicConfig(filename="nvdcve.log", level=logging.DEBUG, format="%(asctime)s: %(message)s")

title = "GET-NVDCVE"
print("=" * (len(title) + 4))
print("| " + title + " |")
print("=" * (len(title) + 4))

# Parse the command line arguments
parser = argparse.ArgumentParser()
parser.add_argument("-y", "--year", type=int, help="Download data for specific year (yyyy)")
parser.add_argument("-o", "--output", type=str, help="Output format (json, csv, text)")
parser.add_argument("-d", "--directory", type=str, help="Output directory")
args = parser.parse_args()

# Set default output format to text
output_format = "text"
if args.output and args.output.lower() in ["json", "csv"]:
    output_format = args.output.lower()

# Set default directory to nvd
directory = "nvd"
if args.directory:
    directory = args.directory
if not os.path.exists(directory):
    os.makedirs(directory)

try:
    # Verify SSL certificate for secure connection
    r = requests.get('https://nvd.nist.gov/vuln/data-feeds#JSON_FEED', verify=True)
    r.raise_for_status()
except requests.exceptions.RequestException as e:
    logging.error("An error occurred while connecting to the server: %s" % e)
    sys.exit(1)

with concurrent.futures.ThreadPoolExecutor() as executor:
    for filename in re.findall("nvdcve-1.1-[0-9]*\.json\.zip",r.text):
        # Check if year is specified and continue to next iteration if the year is not in filename
        if args.year:
            if str(args.year) not in filename:
                continue
        
        # Use session to persist the connection and reuse it
        with requests.Session() as session:
            session.mount('https://', requests.adapters.HTTPAdapter(max_retries=3))
            try:
                r_file = session.get("https://static.nvd.nist.gov/feeds/json/cve/1.1/" + filename, stream=True)
                r_file.raise_for_status()
            except requests.exceptions.RequestException as e:
                logging.error("An error occurred while downloading the file: %s" % e)
                continue
            # Check if file already exists and compare sha256
            file_path = os.path.join(directory, filename)
            if os.path.exists(file_path):
                with open(file_path, 'rb') as f:
                    current_sha256 = hashlib.sha256(f.read()).hexdigest()
                if current_sha256 == r_file.headers.get("X-Content-SHA256"):
                    continue
            # Unzip the file
            with open(file_path, 'wb') as f:
                for chunk in r_file.iter_content(chunk_size=8192):
                    # write the content to the file in chunks to avoid memory exhaustion
                    f.write(chunk)
                    downloaded = f.tell()
                    print("Downloaded %.2f%% of %s" % (downloaded / int(r_file.headers['Content-Length']) * 100, filename))
            with zipfile.ZipFile(file_path, "r") as zip_ref:
                zip_ref.extractall(directory)
            try:
            try:
                with open("nvdcve.log", "a") as logfile:
                    logfile.write("Downloaded %s\n" % filename)
            except PermissionError as e:
                logging.error("PermissionError: %s" % e)
                print("PermissionError: %s" % e)

    # Show summary of downloaded files
    try:
        print("-"*120)
        print("Summary:".rjust(70))
        print("-"*120)
        print("Filename".ljust(30), "Size".rjust(20), "sha256".rjust(50))
        print("-"*120)
        if output_format == "csv":
            with open("summary.csv", 'w', newline='') as f_out:
                writer = csv.writer(f_out)
                writer.writerow(["Filename", "Size", "SHA256"])
                for filename in os.listdir(directory):
                    file_path = os.path.join(directory, filename)
                    file_size = os.path.getsize(file_path)
                    with open(file_path, 'rb') as f:
                        sha256 = hashlib.sha256(f.read()).hexdigest()
                    writer.writerow([filename, file_size, sha256])
        elif output_format == "json":
            summary = []
            for filename in os.listdir(directory):
                file_path = os.path.join(directory, filename)
                file_size = os.path.getsize(file_path)
                with open(file_path, 'rb') as f:
                    sha256 = hashlib.sha256(f.read()).hexdigest()
                summary.append({
                    "filename": filename,
                    "size": file_size,
                    "sha256": sha256
                })
            with open("summary.json", "w") as f_out:
                json.dump(summary, f_out, indent=4)
        else:
            with open("summary.txt", 'w') as f_out:
                for filename in os.listdir(directory):
                    file_path = os.path.join(directory, filename)
                    file_size = os.path.getsize(file_path)
                    with open(file_path, 'rb') as f:
                        sha256 = hashlib.sha256(f.read()).hexdigest()
                    f_out.write("%s\t%d\t%s\n" % (filename, file_size, sha256))
                    print(filename.ljust(30), str(file_size).rjust(20), sha256.rjust(50))
        print("-"*120)
    except FileNotFoundError as e:
        print(f"Error: {e}")
        logging.error(f"Error: {e}")
    except Exception as e:
        print(f"Error: {e}")
        logging.error(f"Error: {e}")
